<!-- sections/train.html -->
<div>
  <h2 style="color:#7dd3fc;margin-top:0;">LLM Training</h2>
  <p style="color:#9aa6bd;line-height:1.6;font-size:15px;">
    Training covers pretraining and later fine-tuning. Techniques include supervised fine-tuning, LoRA/PEFT for parameter-efficient tuning, and RLHF for alignment.
  </p>

  <h3 style="color:#e6eef6;margin-top:14px;">Common practices</h3>
  <ul style="color:#9aa6bd;line-height:1.6">
    <li>Curating dataset quality & filtering</li>
    <li>Mixed precision & gradient accumulation to fit large batches</li>
    <li>Using LoRA/PEFT to adapt large models cheaply</li>
  </ul>

  <p style="margin-top:12px;color:#9aa6bd">Edit <code>sections/train.html</code> to add commands, config snippets, or notes.</p>
</div>
